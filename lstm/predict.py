import numpy as np
import pandas as pd
from tensorflow.keras.models import load_model 
import joblib 
import os
import requests 
import json
import time 
from datetime import datetime, timedelta
import streamlit as st 

# â”€â”€ ì„¤ì • â”€â”€
MODEL_DIR = "models" 
# API í‚¤ëŠ” os.getenv('__api_key')ë¥¼ í†µí•´ app.pyì—ì„œ ë¡œë“œëœ .env ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
API_MODEL_NAME = "gemini-2.5-flash-preview-09-2025" 

def add_technical_indicators(df):
    """
    LSTM í•™ìŠµì— ì‚¬ìš©ëœ 7ê°€ì§€ ê¸°ìˆ ì  ì§€í‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    (SMA_5, SMA_20, RSI, MACD, Volume_SMA)
    """
    df = df.copy()
    
    # 1. ì´ë™ í‰ê· ì„  (SMA)
    df['SMA_5'] = df['Close'].rolling(5).mean()
    df['SMA_20'] = df['Close'].rolling(20).mean()
    
    # 2. RSI (Relative Strength Index)
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
    # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
    rs = gain / loss.replace(0, 1e-6) 
    df['RSI'] = 100 - (100 / (1 + rs))
    
    # 3. MACD (Moving Average Convergence Divergence)
    # adjust=FalseëŠ” Pandasì˜ EWM ê¸°ë³¸ ë™ì‘ì…ë‹ˆë‹¤.
    ema12 = df['Close'].ewm(span=12, adjust=False).mean()
    ema26 = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD'] = ema12 - ema26
    
    # 4. ê±°ë˜ëŸ‰ ì´ë™ í‰ê· 
    df['Volume_SMA'] = df['Volume'].rolling(20).mean()
    
    return df.dropna()

def _generate_mock_interpretation(company, final_predicted_price, change_pct):
    """API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ê°€ìƒ í•´ì„ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    trend = "ìƒìŠ¹ ì¶”ì„¸" if change_pct > 0 else "í•˜ë½ ì¶”ì„¸" if change_pct < 0 else "ë³´í•©ì„¸"
    
    return (
        f"**[ğŸš¨ ë„¤íŠ¸ì›Œí¬/API ì˜¤ë¥˜ë¡œ ì¸í•œ ê°€ìƒ ë¶„ì„ ë¦¬í¬íŠ¸]**\n\n"
        f"í˜„ì¬ {company} ì¢…ëª©ì— ëŒ€í•œ AI ì—°ê²°ì— ì‹¤íŒ¨í•˜ì˜€ìŠµë‹ˆë‹¤. "
        f"ì´ëŠ” API ê¶Œí•œ ë˜ëŠ” í• ë‹¹ëŸ‰ ë¬¸ì œë¡œ ë³´ì…ë‹ˆë‹¤. ì´ ë¦¬í¬íŠ¸ëŠ” **API ì—°ê²°ì´ ë³µêµ¬ëœ í›„** "
        f"ì •ìƒì ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.\n\n"
        f"**LSTM ëª¨ë¸ ë‹¨ìˆœ ì˜ˆì¸¡ ê²°ê³¼:** í–¥í›„ 30ì¼ê°„ {trend}ê°€ ì˜ˆìƒë©ë‹ˆë‹¤. "
        f"30ì¼ í›„ ì˜ˆì¸¡ ì¢…ê°€ëŠ” ì•½ **{final_predicted_price:,.0f} KRW**ì´ë©°, ì´ëŠ” í˜„ì¬ê°€ ëŒ€ë¹„ "
        f"**{change_pct:+.1f}%**ì˜ ë³€ë™ë¥ ì„ ì‹œì‚¬í•©ë‹ˆë‹¤."
    )

def _generate_interpretation(company, current_price, final_predicted_price, change_pct, rsi, volume_trend, df_pred):
    """
    Gemini APIë¥¼ í˜¸ì¶œí•˜ì—¬ LSTM ì˜ˆì¸¡ ê²°ê³¼ì— ëŒ€í•œ ì „ë¬¸ì ì¸ í•´ì„ì„ ìƒì„±í•©ë‹ˆë‹¤.
    df_predëŠ” 'Close' ì»¬ëŸ¼ì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤.
    """
    
    # API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì§ì ‘ ê°€ì ¸ì™€ ìœ íš¨ì„± ê²€ì‚¬ ë° URLì— ëª…ì‹œì ìœ¼ë¡œ ì‚¬ìš©
    API_KEY = os.getenv('__api_key', '').strip()
    
    # í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ Mock ë°ì´í„° ë°˜í™˜
    if not API_KEY:
        print("CRITICAL: API Key not found (__api_key is empty). Falling back to Mock analysis.")
        return _generate_mock_interpretation(company, final_predicted_price, change_pct)
        
    url = (
        f"https://generativelanguage.googleapis.com/v1beta/models/{API_MODEL_NAME}:generateContent"
        f"?key={API_KEY}"
    )
    
    # ğŸš¨ [ìˆ˜ì •]: df_predê°€ 'Close' ì»¬ëŸ¼ì„ ê°€ì§€ë¯€ë¡œ, 'ì¢…ê°€' ëŒ€ì‹  'Close'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    # LLM ë¶„ì„ì„ ìœ„í•´ ì˜ˆì¸¡ ì¶”ì´ ë³€ë™ì„±ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    analysis_data = {
        "ì¢…ëª©": company,
        "í˜„ì¬ê°€": f"{current_price:,.0f} KRW",
        "30ì¼ í›„ ì˜ˆì¸¡ê°€": f"{final_predicted_price:,.0f} KRW",
        "ì˜ˆìƒ ë“±ë½ë¥ ": f"{change_pct:+.1f}%",
        "RSI": f"{rsi:.1f}",
        "ê±°ë˜ëŸ‰ ì¶”ì„¸": volume_trend,
        "10ì¼ ê°€ê²© ë³€ë™ì„± (ì´ˆê¸°, ì¤‘ê¸°, í›„ê¸°)": {
            "ì´ˆê¸° 10ì¼ ë³€ë™ (%)": (df_pred['Close'].iloc[9] - current_price) / current_price * 100,
            "ì¤‘ê¸° 10ì¼ ë³€ë™ (%)": (df_pred['Close'].iloc[19] - df_pred['Close'].iloc[9]) / df_pred['Close'].iloc[9] * 100,
            "í›„ê¸° 10ì¼ ë³€ë™ (%)": (df_pred['Close'].iloc[29] - df_pred['Close'].iloc[19]) / df_pred['Close'].iloc[19] * 100,
        }
    }
    
    system_prompt = (
        "ë‹¹ì‹ ì€ ì¸ê³µì§€ëŠ¥ ê¸°ë°˜ì˜ ê¸ˆìœµ ê¸°ìˆ  ë¶„ì„ê°€ì…ë‹ˆë‹¤. "
        "ì£¼ì–´ì§„ LSTM ì˜ˆì¸¡ ê²°ê³¼ì™€ í•µì‹¬ ê¸°ìˆ  ì§€í‘œë¥¼ ë°”íƒ•ìœ¼ë¡œ, "
        "ì‹œì¥ì˜ ë³€ë™ì„±, ì¶”ì„¸ì˜ ê°•ë„, ê·¸ë¦¬ê³  ì˜ˆìƒë˜ëŠ” ì£¼ê°€ ê¶¤ì ì— ì´ˆì ì„ ë§ì¶˜ "
        "ê°ê´€ì ì´ê³  ê°„ê²°í•œ í•œêµ­ì–´(í•˜ì‹­ì‹œì˜¤ì²´) ì „ë¬¸ê°€ ë¦¬í¬íŠ¸ë¥¼ **5ì¤„ ì´ìƒ**ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. "
        "ì ˆëŒ€ë¡œ 'íˆ¬ì ì¡°ì–¸', 'ë§¤ìˆ˜', 'ë§¤ë„', 'ì¶”ì²œ' ë“±ì˜ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤."
    )
    
    user_query = (
        f"LSTM ëª¨ë¸ì´ ì˜ˆì¸¡í•œ '{company}'ì˜ í–¥í›„ 30ì¼ ì£¼ê°€ ì¶”ì´ ë° ê¸°ìˆ ì  ì§€í‘œ ë¶„ì„ ë°ì´í„°ì…ë‹ˆë‹¤. "
        f"ì´ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì „ë¬¸ì ì¸ í•´ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”. "
        f"ë¶„ì„ ë°ì´í„°: {json.dumps(analysis_data, ensure_ascii=False)}"
    )

    payload = {
        "contents": [{"parts": [{"text": user_query}]}],
        "systemInstruction": {"parts": [{"text": system_prompt}]},
        "tools": [{"google_search": {}}], 
    }
    
    # API í˜¸ì¶œ (ì§€ìˆ˜ ë°±ì˜¤í”„ ì ìš©)
    max_retries = 5
    for attempt in range(max_retries):
        try:
            response = requests.post(url, headers={'Content-Type': 'application/json'}, data=json.dumps(payload), timeout=30)
            response.raise_for_status() 
            result = response.json()
            
            # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = result.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', 'í•´ì„ì„ ìƒì„±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')
            return text
            
        except requests.exceptions.RequestException as e:
            if response.status_code == 403:
                 print(f"CRITICAL 403 ERROR: API Key or Quota issue suspected. URL check: {url}")
            
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt
                print(f"[{attempt + 1}/{max_retries}] API ìš”ì²­ ì‹¤íŒ¨: {e}. {wait_time}ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤.") 
                time.sleep(wait_time)
            else:
                error_msg = "ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë˜ëŠ” API í˜¸ì¶œ í•œë„ ì´ˆê³¼ë¡œ ì¸í•´ ì˜ˆì¸¡ í•´ì„ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                print(f"ìµœì¢… ì‹¤íŒ¨: {error_msg}")
                return _generate_mock_interpretation(company, final_predicted_price, change_pct)
        except Exception as e:
            print(f"ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return "ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í•´ì„í•˜ëŠ” ì¤‘ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            
    return _generate_mock_interpretation(company, final_predicted_price, change_pct)


def predict_next_month(df, symbol, time_steps, company): 
    """ì €ì¥ëœ ë‹¤ë³€ëŸ‰ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ 30ì¼ ì£¼ê°€ë¥¼ ì˜ˆì¸¡í•˜ê³  LLM í•´ì„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    safe = symbol.replace(".", "_")
    scaler_path = os.path.join(MODEL_DIR, f"scaler_{safe}_{time_steps}.pkl")
    model_path = os.path.join(MODEL_DIR, f"model_{safe}_{time_steps}.keras") 

    if not os.path.exists(scaler_path) or not os.path.exists(model_path):
        return None, None, f"'{company}' ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. 'LSTM í•™ìŠµ ë° 30ì¼ ì˜ˆì¸¡ ì‹œì‘' ë²„íŠ¼ìœ¼ë¡œ ìë™ í•™ìŠµí•˜ì„¸ìš”."

    try:
        scaler = joblib.load(scaler_path)
        model = load_model(model_path)
    except Exception as e:
        return None, None, f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ({e}). ì¬í•™ìŠµ í›„ ì¬ì‹œë„í•˜ì„¸ìš”."

    # 1. ì˜ˆì¸¡ì— í•„ìš”í•œ ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€
    df_proc = add_technical_indicators(df.copy())
    features = ['Close', 'Volume', 'SMA_5', 'SMA_20', 'RSI', 'MACD', 'Volume_SMA']
    
    if len(df_proc) < time_steps:
        return None, None, "ê¸°ìˆ  ì§€í‘œ ìƒì„± í›„ ê³¼ê±° ë°ì´í„° ë¶€ì¡± (time_stepsë³´ë‹¤ ì§§ìŒ)"

    # 2. ìŠ¤ì¼€ì¼ë§ ë° ìµœê·¼ ë°ì´í„° ì¤€ë¹„
    data_scaled = scaler.transform(df_proc[features].values) 
    recent = data_scaled[-time_steps:] # (time_steps, 7)
    
    # 3. ì˜ˆì¸¡ ë£¨í”„ (ì•ˆì •í™”ëœ ë¡œì§ ì ìš©)
    predictions = []
    current_input = recent.reshape(1, time_steps, len(features)) # (1, time_steps, 7)

    for _ in range(30):
        # ì˜ˆì¸¡ ìˆ˜í–‰
        predicted_scaled_price = model.predict(current_input, verbose=0)[0, 0]
        predictions.append(predicted_scaled_price)
        
        # ë‹¤ìŒ ë‹¨ê³„ì˜ ì…ë ¥ ì‹œí€€ìŠ¤ ì¤€ë¹„
        # 1. ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤(time_steps - 1)ì˜ ëª¨ë“  í”¼ì²˜ë¥¼ ë³µì‚¬
        temp_scaled = current_input[0, -1].copy()
        
        # 2. Close ê°’(ì¸ë±ìŠ¤ 0)ì„ ì˜ˆì¸¡ëœ ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸
        temp_scaled[0] = predicted_scaled_price

        # 3. ìƒˆë¡œìš´ ì‹œí€€ìŠ¤ ìƒì„± (ì²« ë²ˆì§¸ ìš”ì†Œë¥¼ ì œê±°í•˜ê³  ë§ˆì§€ë§‰ì— ìƒˆ ìš”ì†Œë¥¼ ì¶”ê°€)
        new_scaled_sequence = np.append(current_input[0, 1:], [temp_scaled], axis=0)
        current_input = new_scaled_sequence.reshape(1, time_steps, len(features))

    # 4. ì—­ë³€í™˜
    dummy = np.zeros((30, len(features)))
    dummy[:, 0] = predictions # ì˜ˆì¸¡ëœ ì¢…ê°€ë§Œ ì²« ë²ˆì§¸ ì»¬ëŸ¼ì— ì±„ì›€
    pred_prices = scaler.inverse_transform(dummy)[:, 0]

    # 5. ê²°ê³¼ DataFrame ìƒì„±
    last_date = df.index[-1]
    dates = [last_date + timedelta(days=i+1) for i in range(30)]
    # ğŸš¨ [ìˆ˜ì •]: ì»¬ëŸ¼ëª…ì„ 'ì¢…ê°€' ëŒ€ì‹  'Close'ë¡œ ì‚¬ìš©
    pred_df = pd.DataFrame({'Close': pred_prices}, index=dates)
    
    # 6. LLM ë¶„ì„ì„ ìœ„í•œ í†µê³„ëŸ‰ ê³„ì‚°
    final_price = float(pred_prices[-1])
    current_price = float(df['Close'].iloc[-1])
    change_pct = (final_price - current_price) / current_price * 100 if current_price != 0 else 0
    
    # RSIì™€ ê±°ë˜ëŸ‰ ì¶”ì„¸ëŠ” ì§€í‘œê°€ ì¶”ê°€ëœ df_procì—ì„œ ê°€ì ¸ì˜´
    rsi = df_proc['RSI'].iloc[-1]
    volume_trend = "ì¦ê°€" if df['Volume'].iloc[-1] > df['Volume'].mean() else "ê°ì†Œ"
    
    # 7. LLM í•´ì„ ìƒì„±
    interpretation = _generate_interpretation(
        company=company,
        current_price=current_price,
        final_predicted_price=final_price,
        change_pct=change_pct,
        rsi=rsi,
        volume_trend=volume_trend,
        df_pred=pred_df # 'Close' ì»¬ëŸ¼ì„ ê°€ì§„ df_pred ì „ë‹¬
    )
    
    return pred_df, final_price, interpretation