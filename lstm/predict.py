import numpy as np
import pandas as pd
from tensorflow.keras.models import load_model # kerasì—ì„œ tensorflow.kerasë¡œ ë³€ê²½í•˜ì—¬ í˜¸í™˜ì„± ê°•í™”
import joblib 
import os
import requests 
import json
import time 
from datetime import timedelta
from dotenv import load_dotenv
load_dotenv() 
# â”€â”€ ì„¤ì • â”€â”€
MODEL_DIR = "models" # ëª¨ë¸ ì €ì¥ í´ë”

# API í˜¸ì¶œ ì‹œ ì¬ì‹œë„ ê´€ë ¨ ì„¤ì •
API_MODEL_NAME = "gemini-2.5-flash-preview-09-2025"

def _generate_interpretation(company, df_actual, df_pred):
    """
    Gemini APIë¥¼ í˜¸ì¶œí•˜ì—¬ LSTM ì˜ˆì¸¡ ê²°ê³¼ì— ëŒ€í•œ ì „ë¬¸ì ì¸ í•´ì„ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    
    # 1. API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. (GEMINI_API_KEY ë˜ëŠ” __api_key í™˜ê²½ ë³€ìˆ˜ í™•ì¸)
    # app.pyì—ì„œ ì„¤ì •í•œ GEMINI_API_KEYë¥¼ ìš°ì„  í™•ì¸í•©ë‹ˆë‹¤.
    API_KEY = os.getenv('GEMINI_API_KEY', '').strip()
    
    # ë§Œì•½ GEMINI_API_KEYê°€ ì—†ìœ¼ë©´, íŠ¹ì • í™˜ê²½ ë³€ìˆ˜ì¸ __api_keyë„ í™•ì¸í•©ë‹ˆë‹¤.
    if not API_KEY:
        API_KEY = os.getenv('__api_key', '').strip()

    # 2. í‚¤ê°€ ìœ íš¨í•œì§€ í™•ì¸í•©ë‹ˆë‹¤.
    if not API_KEY or API_KEY == 'YOUR_ACTUAL_GEMINI_API_KEY':
        print("ê²½ê³ : Gemini API í‚¤ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. LLM ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return (
            "ğŸ”´ LLM í•´ì„ ì‹¤íŒ¨: API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
            "`app.py` íŒŒì¼ ìƒë‹¨ì—ì„œ **ìœ íš¨í•œ í‚¤**ë¡œ êµì²´í•˜ê³  ì €ì¥í–ˆëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”."
        )

    # ì˜ˆì¸¡ëœ 30ì¼ ë°ì´í„° ì¶”ì´ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    start_price = df_actual['Close'].iloc[-1]
    final_price = df_pred['Close'].iloc[-1]
    
    # 10ì¼ ë‹¨ìœ„ë¡œ ë³€ë™ë¥  ê³„ì‚° (ì¶”ì´ ë¶„ì„ì„ ìœ„í•¨)
    segments = [10, 20, 30]
    trend_analysis = []
    
    for i, day in enumerate(segments):
        if day <= len(df_pred):
            end_price = df_pred['Close'].iloc[day-1]
            
            if i == 0:
                base_price = start_price
                period_name = "ì´ˆê¸° 10ì¼ (í˜„ì¬ ì¢…ê°€ ëŒ€ë¹„)"
            elif i == 1:
                base_price = df_pred['Close'].iloc[9] 
                period_name = "ì¤‘ê¸° 10ì¼ (10ì¼ì°¨ ì¢…ê°€ ëŒ€ë¹„)"
            else: # day == 30
                base_price = df_pred['Close'].iloc[19] 
                period_name = "í›„ê¸° 10ì¼ (20ì¼ì°¨ ì¢…ê°€ ëŒ€ë¹„)"
            
            # ì´ì „ ì‹œì  ëŒ€ë¹„ ë³€ë™ë¥ 
            change = (end_price - base_price) / base_price * 100
            
            trend_analysis.append({
                "period": period_name,
                "price": f"{end_price:,.0f} KRW",
                "change_pct": f"{change:+.2f}%"
            })

    total_change = (final_price - start_price) / start_price * 100
    
    analysis_data = {
        "company": company,
        "current_price": f"{start_price:,.0f} KRW",
        "final_predicted_price": f"{final_price:,.0f} KRW",
        "total_change_pct": f"{total_change:+.2f}%",
        "trend_segments": trend_analysis,
    }

    system_prompt = (
        "ë‹¹ì‹ ì€ LSTM ì£¼ê°€ ì˜ˆì¸¡ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ ê¸°ìˆ  ë¶„ì„ê°€ì…ë‹ˆë‹¤. "
        "ì£¼ì–´ì§„ 10ì¼ ë‹¨ìœ„ì˜ ê°€ê²© ë³€í™”(momentum) ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, "
        "í–¥í›„ 30ì¼ê°„ì˜ ì£¼ê°€ 'íë¦„'ê³¼ 'ë³€ë™ì„±'ì— ì´ˆì ì„ ë§ì¶˜ ì‹¬ì¸µì ì¸ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. "
        "ë¶„ì„ì—ëŠ” ì™œ ì´ëŸ¬í•œ ì¶”ì„¸ê°€ ì˜ˆì¸¡ë˜ì—ˆëŠ”ì§€ì— ëŒ€í•œ ê¸°ìˆ ì  í•´ì„(ì˜ˆ: ì¡°ì •, ëŒíŒŒ ì‹œë„, íš¡ë³´ íŒ¨í„´)ì„ í¬í•¨í•˜ê³ , "
        "ì˜ˆìƒë˜ëŠ” ì£¼ê°€ ê¶¤ì ì„ ëª…í™•íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”. ë³´ê³ ì„œëŠ” ê°ê´€ì ì´ê³  ê°„ê²°í•œ í•œ ë‹¨ë½ì˜ í•œêµ­ì–´(í•˜ì‹­ì‹œì˜¤ì²´)ì—¬ì•¼ í•©ë‹ˆë‹¤."
    )
    
    user_query = (
        f"LSTM ëª¨ë¸ì´ ì˜ˆì¸¡í•œ '{company}'ì˜ í–¥í›„ 30ì¼ ì£¼ê°€ ì¶”ì´ ë°ì´í„°ì…ë‹ˆë‹¤. ì´ ë°ì´í„°ë¥¼ "
        f"ë¶„ì„í•˜ì—¬ ì˜ˆì¸¡ ê²°ê³¼ì— ëŒ€í•œ ì „ë¬¸ì ì¸ í•´ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”. "
        f"ë¶„ì„ ë°ì´í„°: {json.dumps(analysis_data, ensure_ascii=False)}"
    )

    url = f"https://generativelanguage.googleapis.com/v1beta/models/{API_MODEL_NAME}:generateContent?key={API_KEY}"
    payload = {
        "contents": [{"parts": [{"text": user_query}]}],
        "systemInstruction": {"parts": [{"text": system_prompt}]},
    }
    
    # API í˜¸ì¶œ (ì§€ìˆ˜ ë°±ì˜¤í”„ ì ìš©)
    for attempt in range(5):
        try:
            response = requests.post(url, headers={'Content-Type': 'application/json'}, data=json.dumps(payload))
            response.raise_for_status() 
            result = response.json()
            
            text = result.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', 'í•´ì„ì„ ìƒì„±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')
            return text
            
        except requests.exceptions.RequestException as e:
            if attempt < 4:
                wait_time = 2 ** attempt
                print(f"API ìš”ì²­ ì‹¤íŒ¨: {e}. {wait_time}ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤.")
                time.sleep(wait_time)
            else:
                print(f"ìµœì¢… API ìš”ì²­ ì‹¤íŒ¨: {e}")
                return "ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë˜ëŠ” API í˜¸ì¶œ í•œë„ ì´ˆê³¼ë¡œ ì¸í•´ ì˜ˆì¸¡ í•´ì„ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        except Exception as e:
            print(f"ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return "ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í•´ì„í•˜ëŠ” ì¤‘ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    return "ì˜ˆì¸¡ í•´ì„ ìƒì„± ì‹¤íŒ¨ (ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼)."


def predict_next_month(df, symbol, time_steps, company): 
    """ì €ì¥ëœ ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ 30ì¼ ì£¼ê°€ë¥¼ ì˜ˆì¸¡í•˜ê³  LLM í•´ì„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    # .ì„ _ë¡œ ì¹˜í™˜í•˜ì—¬ íŒŒì¼ ê²½ë¡œ ì•ˆì „í•˜ê²Œ ë§Œë“¦
    safe_symbol = symbol.replace(".", "_")
    
    # MODEL_DIRì„ modelsë¡œ ë³€ê²½í–ˆìœ¼ë¯€ë¡œ, í•™ìŠµ íŒŒì¼ ê²½ë¡œë„ í™•ì¸ í•„ìš”
    model_path = os.path.join(MODEL_DIR, f"lstm_model_{safe_symbol}_{time_steps}.keras")
    scaler_path = os.path.join(MODEL_DIR, f"scaler_{safe_symbol}_{time_steps}.pkl")

    if not os.path.exists(model_path) or not os.path.exists(scaler_path):
        print(f"Model or scaler file not found. Please train the model first.")
        # ì‚¬ìš©ì í”¼ë“œë°±ì„ ìœ„í•´ ëª¨ë¸ í´ë” ì´ë¦„ì„ ì •í™•íˆ ì•Œë ¤ì¤ë‹ˆë‹¤.
        return pd.DataFrame(), None, f"ëª¨ë¸ íŒŒì¼ì´ ì—†ì–´ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ í´ë”ê°€ '{MODEL_DIR}'ì¸ì§€ í™•ì¸í•˜ì„¸ìš”."
    
    try:
        scaler = joblib.load(scaler_path)
        # keras.models.load_model ëŒ€ì‹  tensorflow.keras.models.load_model ì‚¬ìš©
        model = load_model(model_path) 
        
    except Exception as e:
        print(f"Error loading model or scaler: {e}")
        return pd.DataFrame(), None, f"ëª¨ë¸/ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì˜¤ë¥˜: {e}"

    # 'Close' ê°€ê²©ë§Œ ì‚¬ìš©
    data = df.filter(['Close'])
    
    # â”€â”€ 30ì¼ ì˜ˆì¸¡ì„ ìœ„í•œ ë°˜ë³µ ë£¨í”„ â”€â”€
    last_data = data[-time_steps:].values
    last_data_scaled = scaler.transform(last_data)
    
    temp_input = last_data_scaled.flatten().tolist()
    
    lst_output = []
    n_future_days = 30
    
    for i in range(n_future_days):
        if len(temp_input) > time_steps:
            # ì—¬ê¸°ëŠ” í•­ìƒ time_stepsì™€ ê¸¸ì´ê°€ ê°™ê±°ë‚˜ ì‘ì•„ì•¼ í•©ë‹ˆë‹¤.
            # ì˜ˆì¸¡ ë£¨í”„ì˜ ê¸°ë³¸ ë¡œì§ì„ ìœ ì§€í•©ë‹ˆë‹¤.
            x_input = np.array(temp_input[-time_steps:]).reshape((1, time_steps, 1))
        else:
            x_input = np.array(temp_input).reshape((1, time_steps, 1))
            
        y_pred_scaled = model.predict(x_input, verbose=0)
        
        lst_output.append(y_pred_scaled[0, 0])
        temp_input.append(y_pred_scaled[0, 0])
        temp_input = temp_input[1:] 

    # â”€â”€ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì›ë˜ ìŠ¤ì¼€ì¼ë¡œ ì—­ë³€í™˜ ë° DataFrame ìƒì„± â”€â”€
    scaled_predictions_2d = np.array(lst_output).reshape(-1, 1)
    
    # ì—­ë³€í™˜ì„ ìœ„í•œ ë” ì•ˆì „í•œ ë°©ì‹ ì‚¬ìš©
    # ìŠ¤ì¼€ì¼ëŸ¬ê°€ fitëœ featureì˜ ê°œìˆ˜ì™€ ì¼ì¹˜í•˜ë„ë¡ ë”ë¯¸ ë°ì´í„° ìƒì„±
    dummy_input = np.zeros((len(scaled_predictions_2d), scaler.n_features_in_))
    dummy_input[:, 0] = scaled_predictions_2d.flatten()
    
    predictions = scaler.inverse_transform(dummy_input)[:, 0]

    last_date = df.index[-1]
    prediction_dates = [last_date + timedelta(days=i) for i in range(1, n_future_days + 1)]
    
    pred_df = pd.DataFrame(predictions, index=prediction_dates, columns=['Close'])
    final_price = pred_df['Close'].iloc[-1]
    
    # â”€â”€ LLM í•´ì„ ìƒì„± â”€â”€
    interpretation = _generate_interpretation(company, df, pred_df)
    
    return pred_df, final_price, interpretation