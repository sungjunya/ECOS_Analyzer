# data_loader.py (get_english_name ì¶”ê°€ ë²„ì „)

import pandas as pd
import requests
import time
from io import StringIO
from bs4 import BeautifulSoup
import streamlit as st
from datetime import datetime, timedelta
import re
import certifi
import numpy as np
import yfinance as yf # ğŸš¨ yfinance ì„í¬íŠ¸ ì¶”ê°€ (ìƒë‹¨ì— ì´ë¯¸ ìˆì—ˆìœ¼ë‚˜ ì¬í™•ì¸)


def search_stock_code(query):
    query = query.strip()
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
    url = f"https://search.naver.com/search.naver?where=stock&query={query}"
    try:
        resp = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(resp.text, 'html.parser')
        for a in soup.find_all('a', href=True):
            if 'finance.naver.com/item' in a['href']:
                code = a['href'].split('code=')[1].split('&')[0]
                if len(code) == 6 and code.isdigit():
                    symbol = f"{code}.KS"
                    st.success(f"ê²€ìƒ‰ ì„±ê³µ: '{query}' â†’ {symbol}")
                    return symbol
        st.warning(f"ì¢…ëª© ì—†ìŒ: {query}")
        return None
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return None


def parse_money(text: str) -> float:
    """ëª¨ë“  ì¼€ì´ìŠ¤ ì™„ë²½ ì²˜ë¦¬: '595ì¡° 5,156ì–µ', '784ì–µ', '3,578ì¡°' ë“±"""
    if not text or not text.strip():
        return 0.0
    text = re.sub(r"[,\s]", "", text.strip())
    val = 0.0

    # 1. ì¡° ë‹¨ìœ„
    if "ì¡°" in text:
        match = re.search(r"([\d\.]+)ì¡°", text)
        if match:
            val += float(match.group(1))
        text = re.sub(r"[\d\.]*ì¡°", "", text)

    # 2. ì–µ ë‹¨ìœ„ (ì¡°ê°€ ì—†ìœ¼ë©´ ë‚¨ì€ ìˆ«ìëŠ” ë¬´ì¡°ê±´ ì–µìœ¼ë¡œ ê°„ì£¼)
    match = re.search(r"([\d\.]+)", text)
    if match:
        billions = float(match.group(1))
        val += billions / 10_000  # ì–µ â†’ ì¡°

    return round(val, 4)

@st.cache_data(show_spinner=False, ttl=3600)
def get_korean_fundamentals(code: str) -> dict:
    data = {
        "per": None, "pbr": None, "psr": None,
        "foreign_ownership": None, "dividend_yield": None, "market_cap": None
    }

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
        "Accept-Language": "ko-KR,ko;q=0.9"
    }

    try:
        url = f"https://finance.naver.com/item/main.naver?code={code}"
        resp = requests.get(url, headers=headers, timeout=20, verify=certifi.where())
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, "lxml")
    except Exception as e:
        st.warning(f"ì ‘ì† ì‹¤íŒ¨: {e}")
        return data

    # 1. PER, PBR, PSR â†’ ë„¤ì´ë²„ê°€ ì´ë¯¸ ê³„ì‚°í•´ì¤€ ê°’ ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜¤ê¸° (100% ì •í™•)
    for tid, key in [("_per", "per"), ("_pbr", "pbr"), ("_psr", "psr")]:
        tag = soup.find("em", id=tid)
        if tag:
            try:
                val = tag.get_text(strip=True).replace(",", "")
                data[key] = round(float(val), 2)
            except:
                pass

    # 2. ì‹œê°€ì´ì•¡
    mcap_tag = soup.find("em", id="_market_sum")
    if mcap_tag:
        text = mcap_tag.get_text(strip=True)
        text = re.sub(r"[,\s]", "", text)
        val = 0.0
        if "ì¡°" in text:
            t = re.search(r"([\d\.]+)ì¡°", text)
            if t: val += float(t.group(1))
            text = re.sub(r"[\d\.]*ì¡°", "", text)
        if text:
            b = re.search(r"([\d\.]+)", text)
            if b: val += float(b.group(1)) / 10_000
        if val > 0:
            data["market_cap"] = round(val, 2)

    # 3. ì™¸êµ­ì¸ ì§€ë¶„ìœ¨ & ë°°ë‹¹ìˆ˜ìµë¥ 
    full_text = soup.get_text()
    for pat in [r"ì™¸êµ­ì¸[^\d]*([\d,]+\.\d+)%", r"ì™¸êµ­ì¸\s*ì§€ë¶„ìœ¨[^\d]*([\d,]+\.\d+)%"]:
        m = re.search(pat, full_text)
        if m:
            data["foreign_ownership"] = float(m.group(1).replace(",", ""))
            break

    for pat in [r"ë°°ë‹¹ìˆ˜ìµë¥ [^\d]*([\d,]+\.\d+)%", r"ë°°ë‹¹ìˆ˜ìµë¥ \s*\[?[^\d]*([\d,]+\.\d+)%"]:
        m = re.search(pat, full_text)
        if m:
            data["dividend_yield"] = float(m.group(1).replace(",", ""))
            break

    return data


# ğŸš¨ get_english_name í•¨ìˆ˜ ì¶”ê°€ ğŸš¨
@st.cache_data(ttl=3600)
def get_english_name(symbol: str) -> str:
    """
    ì¢…ëª© í‹°ì»¤ë¥¼ ì‚¬ìš©í•˜ì—¬ Yahoo Financeì—ì„œ íšŒì‚¬ ì˜ë¬¸ ì´ë¦„ì„ ê°€ì ¸ì™€ í•„í„°ë§ìš© ì†Œë¬¸ìë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if not symbol:
        return ""
    
    try:
        ticker = yf.Ticker(symbol)
        # longName ë˜ëŠ” shortNameì„ ì‚¬ìš©í•˜ì—¬ ì˜ë¬¸ëª…ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        long_name = ticker.info.get('longName', ticker.info.get('shortName', ''))
        
        if long_name:
            # íŠ¹ìˆ˜ ë¬¸ì ì œê±° ë° ê³µë°± ê¸°ì¤€ìœ¼ë¡œ ì²« 2~3 ë‹¨ì–´ë§Œ ì‚¬ìš©
            cleaned_name = re.sub(r'[^\w\s]', '', long_name)
            # 'SK Hynix Inc' -> 'sk hynix' (ì†Œë¬¸ì, 2ë‹¨ì–´ë§Œ ì‚¬ìš©)
            return ' '.join(cleaned_name.split()[:3]).lower()
            
        return ""
    except Exception:
        # ì•¼í›„ íŒŒì´ë‚¸ìŠ¤ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ ì‹œ, ê¸°ë³¸ ì˜ë¬¸ í‹°ì»¤ ë°˜í™˜
        return symbol.split(".")[0].lower()


@st.cache_data
def load_stock_data(input_text):
    symbol = search_stock_code(input_text)
    if not symbol:
        return pd.DataFrame(), None

    code = symbol.replace('.KS', '')
    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'}
    all_data = []
    max_pages = 30

    with st.spinner(f"[{symbol}] ë°ì´í„° ìˆ˜ì§‘ ì¤‘..."):
        session = requests.Session()
        for page in range(1, max_pages + 1):
            url = f"https://finance.naver.com/item/sise_day.naver?code={code}&page={page}"
            try:
                resp = session.get(url, headers=headers, timeout=10)
                df_page = pd.read_html(StringIO(resp.text), flavor='lxml')[0].dropna()
                if len(df_page) < 7:
                    break
                all_data.append(df_page)
                time.sleep(0.05)
            except:
                break

    if not all_data:
        return pd.DataFrame(), symbol

    df = pd.concat(all_data, ignore_index=True)
    df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'], format='%Y.%m.%d', errors='coerce')
    df = df.dropna(subset=['ë‚ ì§œ'])

    for kr, en in zip(['ì¢…ê°€', 'ì‹œê°€', 'ê³ ê°€', 'ì €ê°€', 'ê±°ë˜ëŸ‰'], ['Close', 'Open', 'High', 'Low', 'Volume']):
        df[en] = pd.to_numeric(df[kr].astype(str).str.replace(',', ''), errors='coerce')

    df = df.set_index('ë‚ ì§œ').sort_index()[['Open', 'High', 'Low', 'Close', 'Volume']].dropna()

    if len(df) < 90:
        st.error(f"ë°ì´í„° ë¶€ì¡±: {len(df)}ì¼")
        return pd.DataFrame(), symbol

    st.success(f"ë¡œë“œ ì™„ë£Œ: {len(df)}ì¼")
    return df, symbol